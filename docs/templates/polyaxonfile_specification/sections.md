## Version

Represents the polyaxon file specification version.

Example:

```yaml
version: 1
```

## Kind

Represents the polyaxon file specification kind, i.e. one of the values `experiment`, `group`, `job`, `notebook`, `tensorboard`, `pipeline`.

Example:

```yaml
kine: experiment
```

## logging

Defines the logging behavior for your execution, this subsection accepts:

 * `level`: The log level.
 * `formatter`: The log formatter regex.


Example:

```yaml
logging:
  level: INFO
```

```yaml
logging:
  level: WARNING
```

## hptuning

Settings defines `seed`, `concurrency`, `search algorithm`, `early_stopping`, `matrix`.
In general the hptuning defines some values that must be unique for
all experiments created based on the polyaxonfile.

### seed

A seed to use when generating random values during the hyperparameters search.

Example:

```yaml
seed: 3234
```

### concurrency

Defines how many experiments to run concurrently when the polyaxon file use a `matrix` section.
This option will be ignored if the polyaxon file only have one independent experiment.

Example:

```yaml
concurrency: 3
```

### matrix

The matrix section works the same way as travisCI matrix section,
and it basically creates multiple specifications.
The way it does that is depend on the methods used to define the hyperparameters and the search algorithm:

 * In the case of grid search, the matrix space is defined by the Cartesian Product of all your defined parameters.
 it is important that only discrete methods are used with grid search.

 * In the case of random search, hyperband, and bayesian optimization, the space search is defined based on sampling,
 from the provided distributions, if discrete values are provided sampling is done uniformly, unless `pvalues` is provided.

The matrix also defines variables same way the `declarations` does, the only difference is
that all the values generated by the matrix contribute to the definition of an experiment group.
Each experiment in this group is defined based on a combination of the values declared in the matrix.

The matrix is defined as `{key: value}` object where the key is the name of the parameter
you are defining and the value is one of these options:


#### Discrete values

 * `values`: a list of values, e.g.

    * `[1, 2, 3, 4]`

 * `range`: [start, stop, step] same way you would define a range in python, e.g.

    * `[1, 10, 2]`
    * `{start: 1, stop: 10, step: 2}`
    * `'1:10:2'`

 * `linspace`: [start, stop, num] steps from start to stop spaced evenly on a `linear scale`, e.g.

    * `[1, 10, 5]`
    * `{start: 1, stop: 10, num: 20}`
    * `'1:2:20'`

 * `logspace`: [start, stop, num] steps from start to stop spaced evenly on a `log scale`, e.g.

    * `[1, 10, 5]`
    * `{start: 1, stop: 10, num: 20}`
    * `'1:2:20'`

 * `geomspace`: [start, stop, num] steps from start to stop, numbers spaced evenly on a log scale (a geometric progression).

    * `[1, 10, 5]`
    * `{start: 1, stop: 10, num: 20}`
    * `'1:2:20'`

#### Distributions

 * `pvalues`: Draws a value_i from values with probability  prob_i, e.g.

    * [(value1, prob1), (value2, prob12), (value3, prob3), ...]

 * `uniform`: Draws samples from a uniform distribution over the half-open interval `[low, high)`, e.g.

    * 0:1
    * [0, 1]
    * {'low': 0, 'high': 1}

 * `quniform`: Draws samples from a quantized uniform distribution over [low, high], `round(uniform(low, high) / q) * q`, e.g.

    * 0:1
    * [0, 1]
    * {'low': 0, 'high': 1}

 * `loguniform`: Draws samples from a log uniform distribution over [low, high], e.g.

    * 0:1
    * [0, 1]
    * {'low': 0, 'high': 1}

 * `qloguniform`: Draws samples from a quantized log uniform distribution over [low, high]

    * 0:1
    * [0, 1]
    * {'low': 0, 'high': 1}

 * `normal`: Draws random samples from a normal (Gaussian) distribution defined by [loc, scale]

    * 0:1
    * [0, 1]
    * {'loc': 0, 'loc': 1}

 * `qnormal`: Draws random samples from a quantized normal (Gaussian) distribution defined by [loc, scale]

    * 0:1
    * [0, 1]
    * {'loc': 0, 'loc': 1}

 * `lognormal`: Draws random samples from a log normal (Gaussian) distribution defined by [loc, scale]

    * 0:1
    * [0, 1]
    * {'loc': 0, 'loc': 1}

 * `qlognormal`: Draws random samples from a quantized log normal (Gaussian) distribution defined by [loc, scale]

    * 0:1
    * [0, 1]
    * {'loc': 0, 'loc': 1}


Example:

```yaml
matrix:
  lr:
    logspace: 0.01:0.1:5

  loss:
    values: [MeanSquaredError, AbsoluteDifference]
```

```yaml
matrix:
  lr:
    uniform: 0.01:0.8

  loss:
    pvalues: [(MeanSquaredError, 0,2), (AbsoluteDifference, 0.8)]
```

These values can be accessed in the following way:

```yaml
--lr={{ lr }} --loss={{ loss }}
```

You can, of course, only access one generated value at a time,
and the value is chosen directly by the algorithm doing the search defined in the `hptuning`.

For each experiment generated during the hyperparameters search, Polyaxon will also add these values
to your declarations, and will export them under the environment variable name `POLYAXON_DECLARATIONS`.

!!! tip "Polyaxon append the matrix value combination to your declarations and export them under the environment variable name `POLYAXON_DECLARATIONS`"
    Check how you can [get the cluster definition](/reference_polyaxon_helper) to use it with your models.


### search algorithm: grid_search

Hyperparameters search using grid search. This the default value when no algorithm is provided.
By default, the grid search will travers all possible combinations based on the cartesian product,
unless `n_experiments` is provided.

Example:

```yaml
grid_search:
  n_experiments: 10
```

### search algorithm: random_search

Hyperparameters search using random search.

Example:

```yaml
random_search:
  n_experiments: 10
```

### search algorithm: hyperband

Hyperparameters search using hyperband.

Example:

```yaml
hyperband:
  max_iter: 81
  eta: 3
  resource:
    name: num_steps
    type: int
  metric:
    name: loss
    optimization: minimize
  resume: False
```

### search algorithm: bo

Hyperparameters search using bayesian optimization.

Example:

```yaml
bo:
  n_iterations: 15
  n_initial_trials: 30
  metric:
    name: loss
    optimization: minimize
  utility_function:
    acquisition_function: ucb
    kappa: 1.2
    gaussian_process:
      kernel: matern
      length_scale: 1.0
      nu: 1.9
      n_restarts_optimizer: 0
```

### early_stopping

Defines a list of metrics and the values for these metrics to stop the search algorithm.

Example:

```yaml
early_stopping:
  - metric: loss
    value: 0.01
    optimization: minimize

  - metric: accuracy
    value: 0.97
    optimization: maximize
```

## Environment

The environment section allows to alter the
resources and configuration of the runtime of your experiments.

Based on this section you can define, how many workers/ps you want to run,
the resources, the node selectors, and the configs of each job.

The values of this section are:

### resources

The resources to use for the job. In the case of distributed run, its the resources to use for the master job.
A resources definition, is optional and made of three optional fields:

 * cpu: {limits: value, requests: value}
 * memory: {limits: value, requests: value}
 * gpu: {limits: value, requests: value}

### outputs

Sometime you experiment or your job might depend on previous jobs or experiments,
and you need to use their outputs to either do fine tuning or post processing of those outputs.

Outputs gives you a way to reference outputs from previous experiments and jobs,
by either using their ids or names (if you gave them name).

This will both mount necessary outputs volumes,
and will expose the paths of those outputs in your experiment/job that requested them.

If you referenced different outputs from jobs and experiments, the paths will following
the same order that was provided.

```yaml
environment:
  outputs:
    jobs: [1, 234, 'job_name1', 'another_username/another_project/job_name2']
    experiments: [12, 'experiment_name', 'my_other_project/experiment_name2']
```


### persistence

The volumes to mount for data and outputs, this is only needed when Polyaxon was deployed
with multiple data volumes or multiple outputs volumes or both.

```yaml
environment:
  persistence:
    data: ['data_volume_name1', 'data_volume_name2', 'data_volume_name3']
    outputs: 'outputs_volume_name2'
```

### node selectors

The labels to use as node selectors for scheduling the job on a specific node.
This subsection provides a way to override the default behavior of Polyaxon,
which schedules experiments and jobs based on node selectors provided during the deployment if they were provided.

```yaml
environment:
  node_selectors:
    node_label: node_value
```

To enable a distributed run, the user can define one of the following framework:

### tensorflow

#### n_workers

The number of workers to use for an experiment.

#### n_ps

The number of parameter server to use for an experiment.

#### default_worker_resources

If specified, it will be the default workers resources.

#### default_ps_resources

If specified, it will be the default ps resources.

#### worker_resources

Defines a specific resources definition for a worker indicated by the index of the worker.

#### ps_resources

Defines a specific resources definition for a ps indicated by the index of the ps.

#### default_worker_node_selectors

If specified, it will be the default workers node selectors.

#### default_ps_node_selectors

If specified, it will be the default ps node selectors.

#### worker_node_selectors

Defines a specific node selectors for a worker indicated by the index of the worker.

#### ps_node_selectors

Defines a specific node selectors for a ps indicated by the index of the ps.

Example:

```yaml

environment:

  node_selectors:
    polyaxon: experiments

  resources:
    cpu:
      requests: 2
      limits: 4
    memory:
      requests: 512
      limits: 2048

  tensorflow:
      n_workers: 4
      n_ps: 1

      worker_node_selectors:
        - index: 3
          polyaxon: special_node

      default_worker_resources:
        cpu:
          requests: 1
          limits: 2
        memory:
          requests: 256
          limits: 1024
        gpu:
          request: 1
          limits: 1

      worker_resources:
        - index: 2
          cpu:
            requests: 1
            limits: 2
          memory:
            requests: 256
            limits: 1024

      ps_resources:
        - index: 0
          cpu:
            requests: 1
            limits: 1
          memory:
            requests: 256
            limits: 1024
```

### mxnet

#### n_workers

The number of workers to use for an experiment.

#### n_ps

The number of parameter server to use for an experiment.

#### default_worker_resources

If specified, it will be the default workers resources.

#### default_ps_resources

If specified, it will be the default ps resources.

#### worker_resources

Defines a specific resources definition for a worker indicated by the index of the worker.

#### ps_resources

Defines a specific resources definition for a ps indicated by the index of the ps.

#### default_worker_node_selectors

If specified, it will be the default workers node selectors.

#### default_ps_node_selectors

If specified, it will be the default ps node selectors.

#### worker_node_selectors

Defines a specific node selectors for a worker indicated by the index of the worker.

#### ps_node_selectors

Defines a specific node selectors for a ps indicated by the index of the ps.

Example:

```yaml

environment:
  mxnet:
    n_workers: 4
    n_ps: 1

    default_ps_node_selectors:
      polyaxon: nodes_for_param_servers
```

### pytorch

#### n_workers

The number of workers to use for an experiment.

#### default_worker_resources

If specified, it will be the default workers resources.

#### worker_resources

Defines a specific resources definition for a worker indicated by the index of the worker.

#### default_worker_node_selectors

If specified, it will be the default workers node selectors.

#### worker_node_selectors

Defines a specific node selectors for a worker indicated by the index of the worker.

Example:

```yaml

environment:
  pytorch:
    n_workers: 4
```

### horovod

#### n_workers

The number of workers to use for an experiment.

#### default_worker_resources

If specified, it will be the default workers resources.

#### worker_resources

Defines a specific resources definition for a worker indicated by the index of the worker.

#### default_worker_node_selectors

If specified, it will be the default workers node selectors.

#### worker_node_selectors

Defines a specific node selectors for a worker indicated by the index of the worker.


Example:

```yaml

environment:
  horovod:
    n_workers: 4
```

## declarations

This section is the appropriate place to declare constants and variables
that will be used by the rest of our specification file.

To declare a simple constant value:

```yaml
declarations:
  batch_size: 128
```

List of values or nested values:

```yaml
declarations:
  layer_units: [100, 200, 10]
```

```yaml
declarations:
  convolutions:
    conv1:
       kernels: [32, 32]
       size: [2, 2]
       strides: [1, 1]
    conv2:
       kernels: [64, 64]
       size: [2, 2]
       strides: [1, 1]
```

This declaration can be used to pass values to our program:

```yaml
 ... --batch-size={{ batch-size }}
```

```yaml
--unit1="{{ layer_units[0] }}" --unit2="{{ layer_units[1] }}" --unit3="{{ layer_units[2] }}"
```


```yaml
--conv1_kernels="{{ convolutions.conv1.kernels }}" --conv1_stides="{{ convolutions.conv1.strides }}" ...
```

The double-brackets is important and indicate that we want to use our declaration.

The declaration are particularly important for descriptive models.

All your declaration will be exported under the environment variable name `POLYAXON_DECLARATIONS`.

!!! tip "Polyaxon export your declarations under environment variable name `POLYAXON_DECLARATIONS`"
    Check how you can [get the experiment declarations](/reference_polyaxon_helper) to use them with your models.

## build

This is where you define how you build an image to run your code.
This section defines the following values/subsections:

 * image [required]: the base image polyaxon will use to build an image for you to run your code.
 * build_steps [optional]: steps are basically a list of ops that Polyaxon use with docker
 `RUN` to install/run further operations you define in the list.
 * env_vars [optional]: environment variables are also a list of tuples of 2 elements, that polyaxon will use to add env variables in the docker image.

```yaml
build:
  image: my_image
  build_steps:
    - pip install PILLOW
    - pip install scikit-learn
  env_vars:
    - [KEY1, VALUE1]
    - [KEY2, VALUE2]
```

## run

This is where you define how you want to run your code.

 * cmd [required]: The command to run during the execution of your code.

```yaml
run:
  cmd: video_prediction_train --num_masks=1
```
